{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "XdELSOEKZfjT"
      },
      "outputs": [],
      "source": [
        "from flask import Flask, request, render_template\n",
        "from tensorflow.keras.models import load_model\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf veinsecure-palm-vein-authentication\n",
        "!git clone https://github.com/anjorisarabhai/veinsecure-palm-vein-authentication.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QsP4f4l2Zl9V",
        "outputId": "cb95a9eb-ce6a-456e-ff64-0f3f1db3203d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'veinsecure-palm-vein-authentication'...\n",
            "remote: Enumerating objects: 362, done.\u001b[K\n",
            "remote: Counting objects: 100% (41/41), done.\u001b[K\n",
            "remote: Compressing objects: 100% (20/20), done.\u001b[K\n",
            "remote: Total 362 (delta 32), reused 22 (delta 21), pack-reused 321 (from 2)\u001b[K\n",
            "Receiving objects: 100% (362/362), 11.94 MiB | 26.13 MiB/s, done.\n",
            "Resolving deltas: 100% (144/144), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/veinsecure-palm-vein-authentication')"
      ],
      "metadata": {
        "id": "pc1JPhQvZ-oW"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!touch /content/veinsecure-palm-vein-authentication/utils/__init__.py"
      ],
      "metadata": {
        "id": "aPeS5AF6aAYV"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O /content/veinsecure-palm-vein-authentication/utils/helpers.py https://raw.githubusercontent.com/anjorisarabhai/veinsecure-palm-vein-authentication/main/utils/helpers.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YpyZzsBDaCFi",
        "outputId": "a9bbfbf8-f387-40b4-f52f-8e9bdadf1a1f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-06-28 07:08:47--  https://raw.githubusercontent.com/anjorisarabhai/veinsecure-palm-vein-authentication/main/utils/helpers.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5753 (5.6K) [text/plain]\n",
            "Saving to: ‘/content/veinsecure-palm-vein-authentication/utils/helpers.py’\n",
            "\n",
            "\r          /content/   0%[                    ]       0  --.-KB/s               \r/content/veinsecure 100%[===================>]   5.62K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-06-28 07:08:47 (85.2 MB/s) - ‘/content/veinsecure-palm-vein-authentication/utils/helpers.py’ saved [5753/5753]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -R /content/veinsecure-palm-vein-authentication"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V2s_wAiwaD40",
        "outputId": "b5d7f9d6-cc7f-4d3f-d140-4b87c9480d10"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/veinsecure-palm-vein-authentication:\n",
            "api  model  notebooks  preprocessing  requirements.txt\tresults  utils\n",
            "\n",
            "/content/veinsecure-palm-vein-authentication/api:\n",
            "applocal.py  app.py\n",
            "\n",
            "/content/veinsecure-palm-vein-authentication/model:\n",
            "evaluate_model.py  train_model.py\n",
            "\n",
            "/content/veinsecure-palm-vein-authentication/notebooks:\n",
            "evaluate_model.ipynb\t\t    Palm_Vein_Preprocess.ipynb\n",
            "palm_vein_baseline_cnn_model.ipynb  README.md\n",
            "Palm_Vein_EDA.ipynb\t\t    train_model.ipynb\n",
            "\n",
            "/content/veinsecure-palm-vein-authentication/preprocessing:\n",
            "palm_vein_preprocess.py  README.md\n",
            "\n",
            "/content/veinsecure-palm-vein-authentication/results:\n",
            "evaluation_summary.csv\tlogs  models  plots\n",
            "\n",
            "/content/veinsecure-palm-vein-authentication/results/logs:\n",
            "training_log.csv\n",
            "\n",
            "/content/veinsecure-palm-vein-authentication/results/models:\n",
            "final_model.h5\n",
            "\n",
            "/content/veinsecure-palm-vein-authentication/results/plots:\n",
            "confusion_matrix.png  learning_curves.png\n",
            "\n",
            "/content/veinsecure-palm-vein-authentication/utils:\n",
            "helperslocal.py  helpers.py  __init__.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(os.listdir('/content/veinsecure-palm-vein-authentication/utils'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MXDAstglaGqE",
        "outputId": "1ee1a091-7909-4d5c-a1f4-05705f24011f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['helpers.py', '__init__.py', 'helperslocal.py']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/veinsecure-palm-vein-authentication/utils\n",
        "!sed -n '1,20p' /content/veinsecure-palm-vein-authentication/utils/helpers.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AIrpNNlUaJbw",
        "outputId": "d5933e7e-29ab-47d0-9b6d-23fc6804be30"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "helperslocal.py  helpers.py  __init__.py\n",
            "# -*- coding: utf-8 -*-\n",
            "\"\"\"helpers.ipynb\n",
            "\n",
            "Automatically generated by Colab.\n",
            "\n",
            "Original file is located at\n",
            "    https://colab.research.google.com/drive/1wZh4H_FGlBCgbYLvhelB5mwziKwCSpig\n",
            "\"\"\"\n",
            "\n",
            "import os\n",
            "\n",
            "# Create the utils directory if it doesn't exist\n",
            "os.makedirs('utils', exist_ok=True)\n",
            "\n",
            "# Full helper code\n",
            "helper_code = '''\n",
            "import os\n",
            "import cv2\n",
            "import numpy as np\n",
            "import matplotlib.pyplot as plt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head -n 165 /content/veinsecure-palm-vein-authentication/utils/helpers.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-OOlT9zaLu1",
        "outputId": "326e5c3c-fa1b-4e9f-bb37-17618cfbd962"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# -*- coding: utf-8 -*-\n",
            "\"\"\"helpers.ipynb\n",
            "\n",
            "Automatically generated by Colab.\n",
            "\n",
            "Original file is located at\n",
            "    https://colab.research.google.com/drive/1wZh4H_FGlBCgbYLvhelB5mwziKwCSpig\n",
            "\"\"\"\n",
            "\n",
            "import os\n",
            "\n",
            "# Create the utils directory if it doesn't exist\n",
            "os.makedirs('utils', exist_ok=True)\n",
            "\n",
            "# Full helper code\n",
            "helper_code = '''\n",
            "import os\n",
            "import cv2\n",
            "import numpy as np\n",
            "import matplotlib.pyplot as plt\n",
            "import tensorflow as tf\n",
            "from sklearn.model_selection import train_test_split\n",
            "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
            "from tensorflow.keras.utils import to_categorical\n",
            "\n",
            "def load_processed_images(data_dir, img_size=(128, 128)):\n",
            "    X, y = [], []\n",
            "    class_names = sorted(os.listdir(data_dir))\n",
            "\n",
            "    for class_idx, class_name in enumerate(class_names):\n",
            "        class_path = os.path.join(data_dir, class_name)\n",
            "        if os.path.isdir(class_path):\n",
            "            for img_file in os.listdir(class_path):\n",
            "                if img_file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
            "                    img_path = os.path.join(class_path, img_file)\n",
            "                    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
            "                    if img is not None:\n",
            "                        img = cv2.resize(img, img_size)\n",
            "                        img = img.astype('float32') / 255.0\n",
            "                        X.append(img)\n",
            "                        y.append(class_idx)\n",
            "\n",
            "    X = np.expand_dims(np.array(X), -1)\n",
            "    y = np.array(y)\n",
            "    return X, y, class_names\n",
            "\n",
            "def create_data_generators(X, y_encoded, batch_size=32, augment=True):\n",
            "    y_cat = to_categorical(y_encoded)\n",
            "\n",
            "    X_train, X_temp, y_train, y_temp = train_test_split(\n",
            "        X, y_cat, stratify=y_encoded, test_size=0.3, random_state=42)\n",
            "\n",
            "    y_temp_enc = np.argmax(y_temp, axis=1)\n",
            "\n",
            "    X_val, X_test, y_val, y_test = train_test_split(\n",
            "        X_temp, y_temp, stratify=y_temp_enc, test_size=0.5, random_state=42)\n",
            "\n",
            "    if augment:\n",
            "        train_aug = ImageDataGenerator(\n",
            "            rotation_range=10,\n",
            "            zoom_range=0.1,\n",
            "            width_shift_range=0.1,\n",
            "            height_shift_range=0.1,\n",
            "            horizontal_flip=True\n",
            "        )\n",
            "    else:\n",
            "        train_aug = ImageDataGenerator()\n",
            "\n",
            "    test_aug = ImageDataGenerator()\n",
            "\n",
            "    train_gen = train_aug.flow(X_train, y_train, batch_size=batch_size, shuffle=True)\n",
            "    val_gen = test_aug.flow(X_val, y_val, batch_size=batch_size, shuffle=False)\n",
            "    test_gen = test_aug.flow(X_test, y_test, batch_size=batch_size, shuffle=False)\n",
            "\n",
            "    return train_gen, val_gen, test_gen\n",
            "\n",
            "def create_tf_data_pipeline(X, y_encoded, batch_size=32, buffer_size=512, augment=True):\n",
            "    y_cat = to_categorical(y_encoded)\n",
            "\n",
            "    X_train, X_temp, y_train, y_temp = train_test_split(\n",
            "        X, y_cat, stratify=y_encoded, test_size=0.3, random_state=42)\n",
            "\n",
            "    y_temp_enc = tf.argmax(y_temp, axis=1).numpy()\n",
            "\n",
            "    X_val, X_test, y_val, y_test = train_test_split(\n",
            "        X_temp, y_temp, stratify=y_temp_enc, test_size=0.5, random_state=42)\n",
            "\n",
            "    def augment_fn(image, label):\n",
            "        image = tf.image.random_flip_left_right(image)\n",
            "        image = tf.image.random_brightness(image, max_delta=0.1)\n",
            "        image = tf.image.random_contrast(image, 0.9, 1.1)\n",
            "        return image, label\n",
            "\n",
            "    def prepare_ds(X, y, training=False):\n",
            "        ds = tf.data.Dataset.from_tensor_slices((X, y))\n",
            "        if training and augment:\n",
            "            ds = ds.map(augment_fn, num_parallel_calls=tf.data.AUTOTUNE)\n",
            "        ds = ds.shuffle(buffer_size).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
            "        return ds\n",
            "\n",
            "    train_ds = prepare_ds(X_train, y_train, training=True)\n",
            "    val_ds   = prepare_ds(X_val, y_val, training=False)\n",
            "    test_ds  = prepare_ds(X_test, y_test, training=False)\n",
            "\n",
            "    return train_ds, val_ds, test_ds\n",
            "\n",
            "def visualize_batch(generator_or_dataset, class_names, framework='keras'):\n",
            "    import matplotlib.pyplot as plt\n",
            "\n",
            "    if framework == 'keras':\n",
            "        images, labels = next(generator_or_dataset)\n",
            "    else:\n",
            "        for images, labels in generator_or_dataset.take(1):\n",
            "            images = images.numpy()\n",
            "            labels = labels.numpy()\n",
            "\n",
            "    labels = np.argmax(labels, axis=1) if labels.ndim > 1 else labels\n",
            "\n",
            "    plt.figure(figsize=(10, 8))\n",
            "    for i in range(min(9, len(images))):\n",
            "        plt.subplot(3, 3, i + 1)\n",
            "        plt.imshow(images[i].squeeze(), cmap='gray')\n",
            "        plt.title(class_names[labels[i]])\n",
            "        plt.axis('off')\n",
            "    plt.tight_layout()\n",
            "    plt.show()\n",
            "\n",
            "def build_test_generator(batch_size=32, shuffle=False, target_size=(128, 128), color_mode=\"grayscale\"):\n",
            "    test_dir = \"data/test\"  # Make sure this folder exists with subfolders per class\n",
            "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
            "    test_gen = test_datagen.flow_from_directory(\n",
            "        test_dir,\n",
            "        target_size=target_size,\n",
            "        batch_size=batch_size,\n",
            "        class_mode=\"categorical\",\n",
            "        shuffle=shuffle,\n",
            "        color_mode=color_mode\n",
            "    )\n",
            "    class_names = list(test_gen.class_indices.keys())\n",
            "    return test_gen, class_names\n",
            "\n",
            "def predict_image(file_path, model, class_names, img_size=(128, 128)):\n",
            "    \"\"\"\n",
            "    Predict class of a single palm image.\n",
            "    \"\"\"\n",
            "    import cv2\n",
            "    img = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
            "    if img is None:\n",
            "        raise ValueError(\"Could not read image. Check file path.\")\n",
            "    \n",
            "    img = cv2.resize(img, img_size).astype('float32') / 255.0\n",
            "    img = np.expand_dims(img, axis=(0, -1))  # Shape: (1, 128, 128, 1)\n",
            "\n",
            "    pred_probs = model.predict(img)\n",
            "    pred_class_idx = np.argmax(pred_probs)\n",
            "    pred_class_name = class_names[pred_class_idx]\n",
            "\n",
            "    return pred_class_idx, pred_class_name, float(np.max(pred_probs))\n",
            "'''\n",
            "# Write the file\n",
            "with open(\"/content/veinsecure-palm-vein-authentication/utils/helpers.py\", \"w\") as f:\n",
            "    f.write(helper_code)\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import importlib\n",
        "import utils.helpers\n",
        "importlib.reload(utils.helpers)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6c0A8-XVaPP5",
        "outputId": "d43fb2ad-337b-430e-fa57-2d2620900f73"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ helpers.py updated with loader, generators, pipelines, and batch visualization.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'utils.helpers' from '/content/veinsecure-palm-vein-authentication/utils/helpers.py'>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from utils.helpers import predict_image"
      ],
      "metadata": {
        "id": "ss-ogr2maSkz"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "app = Flask(__name__)"
      ],
      "metadata": {
        "id": "VWkSzA9Vbm01"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git lfs install"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-o-BAHn9cVsg",
        "outputId": "7d91dc64-7e5e-4c75-d00e-b9600e09188e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Git LFS initialized.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model(\"veinsecure-palm-vein-authentication/results/models/final_model.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ScAREn8TcZNm",
        "outputId": "b561a0f2-096f-4cae-99fe-3d706dfb98a4"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure uploads directory exists\n",
        "UPLOAD_FOLDER = \"static/uploads/\"\n",
        "os.makedirs(UPLOAD_FOLDER, exist_ok=True)"
      ],
      "metadata": {
        "id": "-OP11JPncgC-"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@app.route('/')\n",
        "def home():\n",
        "    return \"✅ Flask App Running! (UI coming soon)\""
      ],
      "metadata": {
        "id": "BTYUPo3Ics2X"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    app.run(debug=True)\n",
        "# do not run this cell as of now. if u do then press ctrl+c to quit. flask application won't run through google colab. run it locally using applocal.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ExknB3Ycvw6",
        "outputId": "438f6ad2-97b0-44a3-ad52-0cf84c2cd434"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: on\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug: * Restarting with stat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Build POST route**\n"
      ],
      "metadata": {
        "id": "s7rM3EZIEBLx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# app.py\n",
        "\n",
        "from flask import Flask, request, jsonify\n",
        "import os\n",
        "from tensorflow.keras.models import load_model\n",
        "from utils.helperslocal import predict_image  # ✅ LOCAL PREDICT FUNCTION\n",
        "import logging\n",
        "\n",
        "# Load model and class names\n",
        "#MODEL_PATH = \"final_model.h5\"\n",
        "UPLOAD_FOLDER = \"static/uploads\"\n",
        "\n",
        "app = Flask(__name__)\n",
        "app.config[\"UPLOAD_FOLDER\"] = UPLOAD_FOLDER\n",
        "\n",
        "#model = load_model(MODEL_PATH)\n",
        "model = load_model(\"veinsecure-palm-vein-authentication/results/models/final_model.h5\")\n",
        "class_names = [f\"{i:03d}\" for i in range(1, 42)]  # '001' to '041'\n",
        "\n",
        "\n",
        "# Setup logging\n",
        "logging.basicConfig(filename=\"logs/api.log\", level=logging.INFO)\n",
        "\n",
        "@app.route(\"/\")\n",
        "def home():\n",
        "    return \"✅ Palm Vein Auth API is running.\"\n",
        "\n",
        "@app.route(\"/predict\", methods=[\"POST\"])\n",
        "def predict():\n",
        "    if \"file\" not in request.files:\n",
        "        return jsonify({\"error\": \"No file part\"}), 400\n",
        "\n",
        "    file = request.files[\"file\"]\n",
        "    if file.filename == \"\":\n",
        "        return jsonify({\"error\": \"No selected file\"}), 400\n",
        "\n",
        "    file_path = os.path.join(app.config[\"UPLOAD_FOLDER\"], file.filename)\n",
        "    file.save(file_path)\n",
        "\n",
        "    try:\n",
        "        class_id, class_name, confidence = predict_image(file_path, model, class_names)\n",
        "        logging.info(f\"Predicted: {class_name} (Confidence: {confidence:.2f})\")\n",
        "\n",
        "        return jsonify({\n",
        "            \"predicted_class\": class_name,\n",
        "            \"confidence\": round(confidence, 2),\n",
        "            \"class_id\": int(class_id)\n",
        "        })\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Prediction failed: {str(e)}\")\n",
        "        return jsonify({\"error\": str(e)}), 500\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    app.run(debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R3gUt-QD97E1",
        "outputId": "cc42e4f1-a339-4da3-c88e-6716c6f9d895"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: on\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug: * Restarting with stat\n"
          ]
        }
      ]
    }
  ]
}