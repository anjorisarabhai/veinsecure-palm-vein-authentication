# -*- coding: utf-8 -*-
"""evaluate_model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1G9PLFekUfxtdEj4PrpJuFLqME7lOvYkc

# **Evaluation & Results**
"""

import numpy as np
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
import os
import pandas as pd

from tensorflow.keras.models import load_model
from sklearn.preprocessing import LabelEncoder
from tensorflow.keras.utils import to_categorical

!rm -rf veinsecure-palm-vein-authentication
!git clone https://github.com/anjorisarabhai/veinsecure-palm-vein-authentication.git

import sys
sys.path.append('/content/veinsecure-palm-vein-authentication')

!touch /content/veinsecure-palm-vein-authentication/utils/__init__.py

!wget -O /content/veinsecure-palm-vein-authentication/utils/helpers.py https://raw.githubusercontent.com/anjorisarabhai/veinsecure-palm-vein-authentication/main/utils/helpers.py

!ls -R /content/veinsecure-palm-vein-authentication

import os
print(os.listdir('/content/veinsecure-palm-vein-authentication/utils'))

!ls /content/veinsecure-palm-vein-authentication/utils
!sed -n '1,20p' /content/veinsecure-palm-vein-authentication/utils/helpers.py

!head -n 127 /content/veinsecure-palm-vein-authentication/utils/helpers.py

import importlib
import utils.helpers
importlib.reload(utils.helpers)

from utils.helpers import create_data_generators, load_processed_images

from google.colab import files
uploaded = files.upload()

import zipfile
import os

zip_path = "processed_dataset.zip"
extract_path = "processed_dataset"

with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_path)

print("Extracted to:", extract_path)

!wget https://github.com/anjorisarabhai/veinsecure-palm-vein-authentication/raw/main/processed_dataset.zip
!unzip processed_dataset.zip

"""### **Load data & labels and Create generators**"""

X, y, class_names = load_processed_images("processed_dataset")
le = LabelEncoder()
y_encoded = le.fit_transform(y)
y_cat = to_categorical(y_encoded)

_, _, test_gen = create_data_generators(X, y_encoded, batch_size=32, augment=False)

!git lfs install

"""### **Load the trained model**"""

model = load_model("veinsecure-palm-vein-authentication/results/models/final_model.h5")

"""### **Predict on test set**"""

y_true = []
y_pred = []

for i in range(len(test_gen)):
    x_batch, y_batch = test_gen[i]
    y_true.extend(np.argmax(y_batch, axis=1))
    preds = model.predict(x_batch)
    y_pred.extend(np.argmax(preds, axis=1))
y_pred_probs = model.predict(test_gen)
y_pred = np.argmax(y_pred_probs, axis=1)

"""### **Evaluation metrics**"""

acc = accuracy_score(y_true, y_pred)
prec = precision_score(y_true, y_pred, average='macro', zero_division=0)
rec = recall_score(y_true, y_pred, average='macro', zero_division=0)
f1 = f1_score(y_true, y_pred, average='macro', zero_division=0)

print("Accuracy:", acc)
print("Precision:", prec)
print("Recall:", rec)
print("F1 Score:", f1)

"""### **Save summary to CSV**"""

summary_df = pd.DataFrame({
    "Metric": ["Accuracy", "Precision", "Recall", "F1 Score"],
    "Score": [acc, prec, rec, f1]
})

os.makedirs("results", exist_ok=True)
summary_df.to_csv("results/evaluation_summary.csv", index=False)

"""### **Confusion matrix**"""

cm = confusion_matrix(y_true, y_pred)
plt.figure(figsize=(12, 10))
sns.heatmap(cm, annot=True, fmt='d', xticklabels=class_names, yticklabels=class_names, cmap='Blues')
plt.title("Confusion Matrix")
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.tight_layout()
plt.show()

os.makedirs("results/plots", exist_ok=True)
plt.savefig("results/plots/confusion_matrix.png")
plt.close()

import shutil
shutil.make_archive("results", 'zip', "results")

"""### **Visualize sample predictions with true/pred labels**


"""

import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras.models import load_model

# Get one batch of test data
test_images, test_labels = next(test_gen)  # assuming Keras ImageDataGenerator

# Predict
pred_probs = model.predict(test_images)
pred_labels = np.argmax(pred_probs, axis=1)
true_labels = np.argmax(test_labels, axis=1)

# Plot first 9 predictions
plt.figure(figsize=(10, 8))
for i in range(9):
    plt.subplot(3, 3, i+1)
    plt.imshow(test_images[i].squeeze(), cmap='gray')
    plt.title(f"True: {class_names[true_labels[i]]}\nPred: {class_names[pred_labels[i]]}",
              color='green' if true_labels[i] == pred_labels[i] else 'red')
    plt.axis('off')
plt.tight_layout()
plt.show()

"""### **Analysis of misclassified samples**

"""

import numpy as np
import pandas as pd
from sklearn.metrics import confusion_matrix

# Ensure arrays
class_names_np = np.array(class_names)
num_classes = len(class_names)

# Confusion Matrix
conf_matrix = confusion_matrix(y_true, y_pred, labels=range(num_classes))

# Misclassification Indices
wrong_idx = np.where(y_true != y_pred)[0]
total_test = len(y_true)
total_misclassified = len(wrong_idx)
mis_rate = total_misclassified / total_test * 100

# Misclassified Samples DataFrame
mis_df = pd.DataFrame({
    "Index": wrong_idx,
    "True Label": class_names_np[y_true][wrong_idx],
    "Predicted Label": class_names_np[y_pred][wrong_idx]
})
os.makedirs("results/day10", exist_ok=True)
mis_df.to_csv("results/day10/all_misclassified_samples.csv", index=False)

# Confused Pairs
conf_pairs = (mis_df.groupby(["True Label", "Predicted Label"])
                     .size()
                     .sort_values(ascending=False)
                     .head(5))

# Class-wise Accuracy
class_accuracies = {}
for i in range(num_classes):
    true_total = np.sum(conf_matrix[i])     # total actual for class i
    correct = conf_matrix[i][i]             # true positives
    acc = (correct / true_total * 100) if true_total > 0 else 0
    class_accuracies[class_names[i]] = round(acc, 2)

class_acc_df = pd.DataFrame(list(class_accuracies.items()), columns=["Class", "Accuracy (%)"])
class_acc_df.to_csv("results/day10/class_wise_accuracy.csv", index=False)

# Print Analysis
print("ANALYSIS OF MISCLASSIFIED SAMPLES\n")
print(f"Total test samples: {total_test}")
print(f"Total misclassified: {total_misclassified}")
print(f"Misclassification rate: {mis_rate:.2f}%\n")

print("TOP 5 MOST CONFUSED CLASS PAIRS:")
for (true_cls, pred_cls), count in conf_pairs.items():
    print(f" - {true_cls} â†’ {pred_cls}: {count} times")

print("\n CLASS WISE ACCURACY:")
for cls, acc in class_accuracies.items():
    print(f" - {cls}: {acc}%")

print("\n COMMON ISSUES :")
print("- Visual similarity between certain palm vein patterns")
print("- Class imbalance or underrepresentation in the training set")
print("- Noise, low contrast, or partial visibility in some test samples")
print("- Insufficient variability in training augmentations")


print("\n RECCOMENDATION:")
print("- Add more diverse samples for low-performing classes")
print("- Use stronger data augmentation (brightness, contrast, rotation)")
print("- Consider deeper models or attention-based layers")

print("\n SAVED TO :")
print("- all_misclassified_samples.csv")
print("- class_wise_accuracy.csv in 'results/day10/'")

"""### **Summary table of model performance**"""

from IPython.display import HTML

def highlight_metrics(val):
    """Color cells based on metric thresholds."""
    if isinstance(val, (float, int)):
        if val >= 0.9:
            return 'background-color: #2e7d32; color: white;'  #GREEN
        elif val >= 0.75:
            return 'background-color: #f9a825; color: black;'  #YELLOW
        else:
            return 'background-color: #c62828; color: white;'  #RED
    return ''

styled_df = summary_df.style \
    .applymap(highlight_metrics, subset=['Precision', 'Recall', 'F1-score']) \
    .format({
        'Precision': '{:.3f}',
        'Recall': '{:.3f}',
        'F1-score': '{:.3f}',
        'Support': '{:.0f}'
    }) \
    .set_caption(" <b>MODEL PERFORMANCE SUMMARY BY CLASS </b>") \
    .set_table_styles([
        {'selector': 'caption',
         'props': [('caption-side', 'top'), ('font-size', '18px'), ('font-weight', 'bold')]},
        {'selector': 'th',
         'props': [('background-color', '#212121'), ('color', 'white'), ('font-size', '14px'), ('padding', '10px')]},
        {'selector': 'td',
         'props': [('font-size', '13px'), ('text-align', 'center'), ('padding', '8px')]}
    ]) \
    .set_properties(**{
        'border': '1px solid #333',
        'border-collapse': 'collapse'
    })

HTML(styled_df.to_html())