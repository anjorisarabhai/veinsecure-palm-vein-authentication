# -*- coding: utf-8 -*-
"""Palm_Vein_Preprocess.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1swPg2No6Lqnd3YFPjI395QoT7UYmUDkG

# **Preprocessing**
"""

from google.colab import files

# Upload kaggle.json
print("Please upload your kaggle.json file:")
files.upload()

# Make a directory for Kaggle and move the token there
!mkdir -p ~/.kaggle
!mv kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json
print("Kaggle API token uploaded and configured.")

!pip install kaggle

!kaggle datasets download -d mahdieizadpanah/birjand-university-mobile-palmprint-databasebmpd

import zipfile
import os

zip_file_name = 'birjand-university-mobile-palmprint-databasebmpd.zip'
extracted_folder_name = 'BMPD_Dataset' # You can choose any name for the extracted folder

if os.path.exists(zip_file_name):
    with zipfile.ZipFile(zip_file_name, 'r') as zip_ref:
        zip_ref.extractall(extracted_folder_name)
    print(f"Dataset unzipped to '{extracted_folder_name}'")
else:
    print(f"Error: {zip_file_name} not found. Make sure the download was successful.")

# List the contents to verify
print("Contents of the extracted folder:")
!ls -F {extracted_folder_name}

import os

extracted_folder_name = 'BMPD_Dataset' # Make sure this matches your extraction folder name

if os.path.exists(extracted_folder_name):
    print(f"Contents of '{extracted_folder_name}':")
    # This command lists all files and directories recursively
    !ls -R {extracted_folder_name}
else:
    print(f"Error: The folder '{extracted_folder_name}' does not exist.")
    print("Please check if the dataset was unzipped successfully and the folder name is correct.")

import os
import cv2
import numpy as np
from matplotlib import pyplot as plt

# --- CORRECTED PATH based on your `ls -R` output ---
# The parent folder of 001, 002, etc., is the one with the long name.
# You need to join 'BMPD_Dataset' with this long folder name.
data_dir = os.path.join('BMPD_Dataset', 'Birjand University Mobile Palmprint Database (BMPD)')

image_paths = []
labels = []

# Ensure the data_dir exists before proceeding
if not os.path.exists(data_dir):
    print(f"Error: The specified data directory '{data_dir}' does not exist. Please correct the path.")
else:
    # Iterate through all files in the data_dir and its subdirectories
    for root, dirs, files in os.walk(data_dir):
        for file in files:
            # All your image files are .JPG, so let's explicitly check for that
            if file.lower().endswith('.jpg'):
                image_path = os.path.join(root, file)
                image_paths.append(image_path)

                # --- Labeling Logic ---
                # The label (subject ID) is the name of the immediate parent folder (e.g., '001', '002').
                # os.path.basename(root) will correctly extract '001', '002', etc.
                label = os.path.basename(root)
                labels.append(label)

    print(f"Found {len(image_paths)} images.")

    if len(image_paths) > 0:
        # Example: Load and display a few images
        num_images_to_show = min(5, len(image_paths))
        plt.figure(figsize=(15, 5))
        for i in range(num_images_to_show):
            img_path = image_paths[i]
            img = cv2.imread(img_path)
            if img is not None:
                # OpenCV loads images in BGR, matplotlib expects RGB
                img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

                plt.subplot(1, num_images_to_show, i + 1)
                plt.imshow(img_rgb)
                plt.title(f"Label: {labels[i]}")
                plt.axis('off')
            else:
                print(f"Warning: Could not load image {img_path}")
        plt.show()
    else:
        print("No images found in the specified directory. Check file extensions or deeper nesting.")

"""### **Set up paths and create the processed folder**"""

import os

# Path to raw data (update if renamed)
raw_data_dir = os.path.join('BMPD_Dataset', 'Birjand University Mobile Palmprint Database (BMPD)')

# New folder to save processed images
processed_data_dir = 'processed_dataset'
os.makedirs(processed_data_dir, exist_ok=True)

"""### **Define preprocessing functions (grayscale, resize, normalize)**"""

import cv2
import numpy as np

def preprocess_image(img_path, size=(224, 224)):
    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
    if img is None:
        print(f"[WARN] Could not load {img_path}")
        return None
    img = cv2.resize(img, size)
    img = img / 255.0  # Normalize to [0, 1]
    return img

"""### **Process and save all images**"""

from tqdm import tqdm

processed_count = 0

for root, dirs, files in os.walk(raw_data_dir):
    for file in tqdm(files):
        if file.lower().endswith('.jpg'):
            input_path = os.path.join(root, file)
            rel_path = os.path.relpath(input_path, raw_data_dir)
            output_path = os.path.join(processed_data_dir, rel_path)

            # Preprocess
            processed_img = preprocess_image(input_path)
            if processed_img is not None:
                # Convert to uint8 for saving
                out_img = (processed_img * 255).astype(np.uint8)

                # Make output folder if missing
                os.makedirs(os.path.dirname(output_path), exist_ok=True)

                # Save image
                cv2.imwrite(output_path, out_img)
                processed_count += 1

print(f"\nâœ… Processed and saved {processed_count} images to '{processed_data_dir}'")

"""### **Sample Processed Images**"""

import cv2
import matplotlib.pyplot as plt
import random
import os

# Path to processed dataset
processed_path = 'processed_dataset'
all_files = [os.path.join(dp, f) for dp, dn, filenames in os.walk(processed_path) for f in filenames if f.lower().endswith('.jpg')]

# Display 5 random processed images
num_samples = min(5, len(all_files))
sampled_files = random.sample(all_files, num_samples)

plt.figure(figsize=(15, 5))
for i, file in enumerate(sampled_files):
    img = cv2.imread(file, cv2.IMREAD_GRAYSCALE)
    plt.subplot(1, num_samples, i + 1)
    plt.imshow(img, cmap='gray')
    plt.title(f"{os.path.basename(os.path.dirname(file))}")
    plt.axis('off')
plt.suptitle("Sample Processed Images", fontsize=16)
plt.tight_layout()
plt.show()

"""### **Log the number of processed images per user/class**"""

import os
from collections import defaultdict

# Directory where processed images are stored
processed_path = 'processed_dataset'

# Dictionary to hold count per class
class_counts = defaultdict(int)

# Count images per user/class
for root, dirs, files in os.walk(processed_path):
    for file in files:
        if file.lower().endswith('.jpg'):
            label = os.path.basename(root)  # Folder name is the label (e.g., '001')
            class_counts[label] += 1

# Log the counts
print("\nProcessed Image Count per Class/User:")
for label, count in sorted(class_counts.items()):
    print(f"User {label}: {count} images")

"""### **zipping the processed dataset**"""

!zip -r processed_dataset.zip processed_dataset

"""### **downloading the processed dataset**"""

from google.colab import files
files.download("processed_dataset.zip")

"""### **Create image loader & visualizer functions**"""

import os
import cv2
import numpy as np
import matplotlib.pyplot as plt

#  Loader
def load_palm_images(data_dir, resize_dim=(128, 128), max_users=5, max_images_per_user=2):
    image_paths = []
    labels = []

    print(f" Scanning folder: {data_dir}")
    user_ids = sorted(os.listdir(data_dir))[:max_users]
    print(f" Found {len(user_ids)} users. Loading up to {max_images_per_user} images per user...\n")

    for user_id in user_ids:
        user_path = os.path.join(data_dir, user_id)
        if os.path.isdir(user_path):
            img_files = [f for f in os.listdir(user_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))][:max_images_per_user]
            for img_file in img_files:
                full_path = os.path.join(user_path, img_file)
                image_paths.append(full_path)
                labels.append(user_id)
                print(f" Loaded: {img_file} (User: {user_id})")

    print(f"\n  Total images loaded: {len(image_paths)}\n")
    return image_paths, labels

#  Preprocessing
def preprocess_image(image, size=(128, 128), apply_clahe=True):
    print(f" Preprocessing image...")
    image = cv2.resize(image, size)
    print(f" Resized to {size}")
    if apply_clahe:
        print(f" Applying CLAHE...")
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
        image = clahe.apply(image)
    image = image / 255.0
    print(f" Normalized to range [0, 1]")
    return image

#  Visualizer
def compare_original_vs_processed(image_paths, n=3):
    plt.figure(figsize=(10, 4 * n))
    print(f"\n Showing {n} original vs processed image comparisons:\n")

    for i in range(n):
        path = image_paths[i]
        filename = os.path.basename(path)

        print(f"---\n Image {i+1}: {filename}")
        original = cv2.imread(path, cv2.IMREAD_GRAYSCALE)
        processed = preprocess_image(original.copy())

        # Plot original
        plt.subplot(n, 2, 2*i + 1)
        plt.imshow(original, cmap='gray')
        plt.title(f"Original\n{filename}")
        plt.axis('off')

        # Plot processed
        plt.subplot(n, 2, 2*i + 2)
        plt.imshow(processed, cmap='gray')
        plt.title("Processed (CLAHE + Norm)")
        plt.axis('off')

    plt.suptitle(" Original vs Processed Palm Vein Images", fontsize=14)
    plt.tight_layout()
    plt.show()

# RUN Everything Below This Line

data_dir = os.path.join("BMPD_Dataset", "Birjand University Mobile Palmprint Database (BMPD)")
image_paths, labels = load_palm_images(data_dir, max_users=5, max_images_per_user=2)
compare_original_vs_processed(image_paths, n=5)

"""### **Apply preprocessing pipeline on full dataset**"""

import os
import cv2
import numpy as np
import matplotlib.pyplot as plt

def preprocess_image(image, size=(128, 128), apply_clahe=True):
    image = cv2.resize(image, size)
    if apply_clahe:
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
        image = clahe.apply(image)
    image = image / 255.0
    return image

def preprocess_full_dataset(data_dir, resize_dim=(128, 128), max_users=5, max_images_per_user=5):
    X = []
    y = []

    print(f" Scanning dataset at: {data_dir}")
    user_ids = sorted(os.listdir(data_dir))[:max_users]
    print(f" Found {len(user_ids)} users. Processing up to {max_images_per_user} images per user.")

    for user_id in user_ids:
        user_path = os.path.join(data_dir, user_id)
        if os.path.isdir(user_path):
            img_files = [f for f in os.listdir(user_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))][:max_images_per_user]

            for img_file in img_files:
                img_path = os.path.join(user_path, img_file)
                img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)

                if img is not None:
                    processed = preprocess_image(img, resize_dim)
                    X.append(processed)
                    y.append(user_id)
                    print(f" Processed: {img_file} (User: {user_id})")
                else:
                    print(f"  Failed to load: {img_file} (User: {user_id})")

    print(f"\n Total images processed: {len(X)}")
    return np.array(X), np.array(y)

# Replace with your dataset path if different
data_dir = "BMPD_Dataset/Birjand University Mobile Palmprint Database (BMPD)"

X_preprocessed, y_labels = preprocess_full_dataset(data_dir)

plt.figure(figsize=(12, 4))

for i in range(6):
    plt.subplot(1, 6, i + 1)
    plt.imshow(X_preprocessed[i], cmap='gray')
    plt.title(f"User {y_labels[i]}")
    plt.axis('off')

plt.suptitle(" Sample Preprocessed Palm Vein Images", fontsize=14)
plt.tight_layout()
plt.show()

"""### **Compare original vs processed in a quick plot**"""

import cv2
import matplotlib.pyplot as plt
import numpy as np

def plot_histogram_comparison(original_gray, processed_norm):
    # Ensure both are 2D grayscale images
    if original_gray is None or processed_norm is None:
        print(" Error: One or both images are missing.")
        return

    # Flatten to 1D arrays
    orig_pixels = original_gray.flatten()
    proc_pixels = (processed_norm * 255).astype(np.uint8).flatten()

    # Plot histograms
    plt.figure(figsize=(8, 4))
    plt.hist(orig_pixels, bins=50, alpha=0.6, label='Original', color='gray', edgecolor='black')
    plt.hist(proc_pixels, bins=50, alpha=0.6, label='Processed (CLAHE)', color='orange', edgecolor='black')
    plt.title(" Histogram Comparison: Original vs Processed")
    plt.xlabel("Pixel Intensity")
    plt.ylabel("Frequency")
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    plt.show()


# Load a sample image from your dataset
img = cv2.imread(image_paths[0], cv2.IMREAD_GRAYSCALE)
img_resized = cv2.resize(img, (128, 128))
proc = preprocess_image(img_resized)

# Plot histogram comparison
plot_histogram_comparison(img_resized, proc)